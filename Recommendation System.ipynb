{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c8da598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting BERT embeddings: 100%|█████████████| 567/567 [00:19<00:00, 29.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567, 1)\n",
      "(567, 769)\n",
      "(567, 64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d8585549244216b1de759e49234c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Category:', options=('Acai Bowls', 'Active Life', 'Afghan', 'Afric…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 48s, sys: 2min 58s, total: 6min 47s\n",
      "Wall time: 5min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.on_category_change(category, top_n)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def read_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "##______________Cleanning numerical data________________\n",
    "\n",
    "def clean_numerical_data(data):\n",
    "    numerical_columns = [col for col in data.columns if data[col].dtype in [np.int64, np.float64]]\n",
    "    data[numerical_columns] = data[numerical_columns].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    return data\n",
    "\n",
    "##______________Function to save BERT embeddings to a folder_____________\n",
    "\n",
    "def save_bert_embeddings(all_state_wiki_descriptions, all_state_bert_embeddings, folder_path):\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    with open(os.path.join(folder_path, 'wiki_descriptions.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_state_wiki_descriptions, f)\n",
    "    with open(os.path.join(folder_path, 'bert_embeddings.pkl'), 'wb') as f:\n",
    "        pickle.dump(all_state_bert_embeddings, f)\n",
    "\n",
    "##_____________ Function to load BERT embeddings from a folder____________\n",
    "\n",
    "def load_bert_embeddings(folder_path):\n",
    "    with open(os.path.join(folder_path, 'wiki_descriptions.pkl'), 'rb') as f:\n",
    "        all_state_wiki_descriptions = pickle.load(f)\n",
    "    with open(os.path.join(folder_path, 'bert_embeddings.pkl'), 'rb') as f:\n",
    "        all_state_bert_embeddings = pickle.load(f)\n",
    "    return all_state_wiki_descriptions, all_state_bert_embeddings\n",
    "\n",
    "##______________ Get BERT embeddings for all_state_demo data_______________\n",
    "\n",
    "def get_bert_embeddings(sentences):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for sentence in tqdm(sentences, desc=\"Extracting BERT embeddings\"):\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sentence,                      \n",
    "                            add_special_tokens=True, \n",
    "                            max_length=256,\n",
    "                            truncation=True,\n",
    "                            padding='max_length',\n",
    "                            return_attention_mask=True,   \n",
    "                            return_tensors='pt',     \n",
    "                       )\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_masks)\n",
    "\n",
    "    text_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "    return text_embeddings\n",
    "\n",
    "##________________ Combinning numerical and textutal embeddings for all_state_demo data____________\n",
    "\n",
    "def combine_features(data, bert_embeddings):\n",
    "    scaler = StandardScaler()\n",
    "    numerical_features = [col for col in data.columns if col != 'City' and data[col].dtype in [np.int64, np.float64]]\n",
    "    scaled_features = scaler.fit_transform(data[numerical_features])\n",
    "    combined_features = np.hstack((scaled_features, bert_embeddings))\n",
    "    return combined_features\n",
    "\n",
    "##_________________ Applying PCA for dimensionality reduction_________________\n",
    "\n",
    "def apply_pca(combined_features):\n",
    "    pca = PCA(n_components=64)\n",
    "    data_pca = pca.fit_transform(combined_features)\n",
    "    return data_pca\n",
    "\n",
    "def create_category_dict(data_frame):\n",
    "    category_dict = {}\n",
    "    for category in data_frame[\"Category Title\"].unique():\n",
    "        category_df = data_frame[data_frame[\"Category Title\"] == category]\n",
    "        restaurant_list = [\n",
    "            {\n",
    "                \"state\": row[\"State\"],\n",
    "                \"city\": row[\"City\"],\n",
    "                \"Business Name\": row[\"Business Name\"],\n",
    "                \"Address\": row[\"Address\"],\n",
    "                \"Rating\": row[\"Rating\"],\n",
    "                \"Reviews\": row[\"Combined_Comments\"],\n",
    "                \"Population\": pd.to_numeric(row[\"Population estimates base, April 1, 2020, (V2022)\"].replace(',', ''), errors='coerce'),\n",
    "                \"High School Graduates\": pd.to_numeric(row[\"High school graduate or higher, percent of persons age 25 years+, 2018-2022\"].replace('%', ''), errors='coerce'),\n",
    "                \"Bachelor's Degree or Higher\": pd.to_numeric(row[\"Bachelor's degree or higher, percent of persons age 25 years+, 2018-2022\"].replace('%', ''), errors='coerce'),\n",
    "                \"Median Household Income\": pd.to_numeric(re.sub(r'[\\$,]', '', row[\"Median household income (in 2022 dollars), 2018-2022\"]), errors='coerce'),\n",
    "                \"Per Capita Income\": pd.to_numeric(re.sub(r'[\\$,]', '', row[\"Per capita income in past 12 months (in 2022 dollars), 2018-2022\"]), errors='coerce')\n",
    "            }\n",
    "            for _, row in category_df.iterrows()\n",
    "        ]\n",
    "        category_dict[category] = restaurant_list\n",
    "    return category_dict\n",
    "\n",
    "##________________Applying Sentimental Analysis on Reviews_________________\n",
    "\n",
    "def analyze_sentiment(comment):\n",
    "    analysis = TextBlob(str(comment))\n",
    "    return 'positive' if analysis.sentiment.polarity > 0 else ('negative' if analysis.sentiment.polarity < 0 else 'neutral')\n",
    "\n",
    "def find_top_restaurants_in_category(category_dict, category):\n",
    "    if category in category_dict:\n",
    "        return category_dict[category]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def find_top_restaurants_info(category_dict, category, top_n):\n",
    "    top_restaurants = find_top_restaurants_in_category(category_dict, category)\n",
    "    return [\n",
    "        {\n",
    "            \"Name\": restaurant[\"Business Name\"],\n",
    "            \"City\": restaurant[\"city\"],\n",
    "            \"State\": restaurant[\"state\"]\n",
    "        }\n",
    "        for restaurant in top_restaurants[:top_n]\n",
    "    ]\n",
    "##__________________Finding Similar cities in iowa for the top rated city founded in midwest and within iowa\n",
    "\n",
    "def find_similar_cities_in_iowa(city_name, all_state_demo, iowa_indices, cos_sim_matrix, top_n):\n",
    "    city_index = all_state_demo.index[all_state_demo['City'] == city_name].tolist()[0]\n",
    "    top_similar_indices = np.argsort(cos_sim_matrix[city_index])[::-1][:top_n + 1]  \n",
    "    similar_cities = []\n",
    "    for idx in top_similar_indices:\n",
    "        if idx != city_index:  \n",
    "            similar_city_name = all_state_demo.iloc[iowa_indices[idx]]['City']\n",
    "            if similar_city_name != city_name:  # Exclude the top restaurant city itself\n",
    "                similarity_score = cos_sim_matrix[city_index][idx]\n",
    "                similar_cities.append((similar_city_name, similarity_score))\n",
    "    return similar_cities[:top_n]\n",
    "\n",
    "def main():\n",
    "    # Read the data\n",
    "    restaurants_common = read_data(\"iowa_location_recommendation_system/all_state_rating_rev_common_cities.csv\")\n",
    "    all_state_demo = read_data(\"iowa_location_recommendation_system/all_state_demo_common_cities.csv\")\n",
    "    all_state_demo = clean_numerical_data(all_state_demo)\n",
    "\n",
    "    # Load or get BERT embeddings\n",
    "    bert_folder_path = \"bert_embeddings\"\n",
    "    if os.path.exists(bert_folder_path):\n",
    "        all_state_wiki_descriptions, all_state_bert_embeddings = load_bert_embeddings(bert_folder_path)\n",
    "    else:\n",
    "        # Get BERT embeddings for all_state_demo data\n",
    "        all_state_wiki_descriptions = all_state_demo[\"wiki_description\"].fillna(\"\")\n",
    "        all_state_bert_embeddings = get_bert_embeddings(all_state_wiki_descriptions)\n",
    "        save_bert_embeddings(all_state_wiki_descriptions, all_state_bert_embeddings, bert_folder_path)\n",
    "\n",
    "    # Filter data for Iowa\n",
    "    iowa_demo = all_state_demo[all_state_demo[\"State\"] == \"Iowa\"]\n",
    "\n",
    "    # Get the indices of Iowa cities in the original all_state_demo dataframe\n",
    "    iowa_indices = iowa_demo.index.tolist()\n",
    "\n",
    "    # Get combined features\n",
    "    all_state_combined_features = combine_features(all_state_demo, all_state_bert_embeddings)\n",
    "\n",
    "    # Apply PCA for dimensionality reduction\n",
    "    all_state_data_pca = apply_pca(all_state_combined_features)\n",
    "\n",
    "    # Compute cosine similarity between all_state_data_pca and iowa_data_pca\n",
    "    cos_sim_matrix = cosine_similarity(all_state_data_pca, all_state_data_pca[iowa_indices])\n",
    "\n",
    "    # Create category dictionary\n",
    "    category_dict = create_category_dict(restaurants_common)\n",
    "    for category in sorted(category_dict.keys()):\n",
    "        print(\"-\", category)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        print(\"-------------------------\")\n",
    "        business_type = input(\"Enter the business type (or 'quit' to exit): \")\n",
    "\n",
    "        if business_type.lower() == 'quit':\n",
    "            break\n",
    "\n",
    "        # Finding top restaurants for the entered business type\n",
    "        top_restaurants_info = find_top_restaurants_info(category_dict, business_type, 3)\n",
    "        if top_restaurants_info:\n",
    "            print(f\"Top 3 restaurants for {business_type}:\")\n",
    "            for i, restaurant_info in enumerate(top_restaurants_info, 1):\n",
    "                restaurant_name = restaurant_info['Name']\n",
    "                restaurant_city = restaurant_info['City']\n",
    "                restaurant_state = restaurant_info['State']\n",
    "                print(f\"{i}. Restaurant: {restaurant_name} in {restaurant_city}, {restaurant_state}\")\n",
    "                similar_cities = find_similar_cities_in_iowa(restaurant_city, all_state_demo, iowa_indices, cos_sim_matrix, 3)\n",
    "                print(f\"   Top 3 similar cities in Iowa:\")\n",
    "                for j, (similar_city, similarity_score) in enumerate(similar_cities, 1):\n",
    "                    print(f\"   {j}. {similar_city} (Similarity: {similarity_score})\")\n",
    "        else:\n",
    "            print(f\"No restaurants found for the business type: {business_type}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5687afbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb1a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf212e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9141687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a2a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b82890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting BERT embeddings: 100%|█████████████| 567/567 [00:21<00:00, 26.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT embeddings saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Load the demographic data\n",
    "all_state_demo = pd.read_csv(\"iowa_location_recommendation_system/all_state_demo_common_cities.csv\")\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embeddings(sentences):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for sentence in tqdm(sentences, desc=\"Extracting BERT embeddings\"):\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sentence,                      \n",
    "                            add_special_tokens=True, \n",
    "                            max_length=256,\n",
    "                            truncation=True,\n",
    "                            padding='max_length',\n",
    "                            return_attention_mask=True,   \n",
    "                            return_tensors='pt',     \n",
    "                       )\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_masks)\n",
    "\n",
    "    text_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "    return text_embeddings\n",
    "\n",
    "# File path to save BERT features\n",
    "bert_features_file = \"bert_features.npy\"\n",
    "\n",
    "# Check if BERT features file already exists\n",
    "if not os.path.exists(bert_features_file):\n",
    "    # BERT features file doesn't exist, so extract BERT features\n",
    "    all_state_wiki_descriptions = all_state_demo[\"wiki_description\"].fillna(\"\")\n",
    "    all_state_bert_embeddings = get_bert_embeddings(all_state_wiki_descriptions)\n",
    "    \n",
    "    # Save BERT features\n",
    "    np.save(bert_features_file, all_state_bert_embeddings)\n",
    "    print(\"BERT embeddings saved successfully.\")\n",
    "else:\n",
    "    print(\"BERT embeddings file already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b8a721c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94075d986ab4da992a1eec22805c64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Category:', options=('Acai Bowls', 'Active Life', 'Afghan', 'Afric…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.on_category_change(category, top_n)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Read the restaurants_common DataFrame\n",
    "restaurants_common = pd.read_csv(\"iowa_location_recommendation_system/all_state_rating_rev_common_cities.csv\")\n",
    "\n",
    "# Load the demographic data\n",
    "all_state_demo = pd.read_csv(\"iowa_location_recommendation_system/all_state_demo_common_cities.csv\")\n",
    "\n",
    "# Function to load BERT features\n",
    "def load_bert_features(file_path):\n",
    "    return np.load(file_path)\n",
    "\n",
    "# File path to saved BERT features\n",
    "bert_features_file = \"bert_features.npy\"\n",
    "\n",
    "# Check if BERT features file exists\n",
    "if os.path.exists(bert_features_file):\n",
    "    # Load BERT features from the saved file\n",
    "    all_state_bert_embeddings = load_bert_features(bert_features_file)\n",
    "else:\n",
    "    raise FileNotFoundError(\"BERT embeddings file not found. Please run the script to extract and save BERT embeddings first.\")\n",
    "\n",
    "# Standardize numerical features for all_state_demo data\n",
    "scaler = StandardScaler()\n",
    "numerical_features = [col for col in all_state_demo.columns if col != 'City' and all_state_demo[col].dtype in [np.int64, np.float64]]\n",
    "all_state_scaled_features = scaler.fit_transform(all_state_demo[numerical_features])\n",
    "\n",
    "# Combine numerical and BERT embeddings for all_state_demo data\n",
    "all_state_combined_features = np.hstack((all_state_scaled_features, all_state_bert_embeddings))\n",
    "\n",
    "# Apply PCA for dimensionality reduction for all_state_demo data\n",
    "pca = PCA(n_components=64)\n",
    "all_state_data_pca = pca.fit_transform(all_state_combined_features)\n",
    "\n",
    "# Filter data for Iowa\n",
    "iowa_demo = all_state_demo[all_state_demo[\"State\"] == \"Iowa\"]\n",
    "\n",
    "# Get the indices of Iowa cities in the original all_state_demo dataframe\n",
    "iowa_indices = iowa_demo.index.tolist()\n",
    "\n",
    "# Compute cosine similarity between all_state_data_pca and iowa_data_pca\n",
    "cos_sim_matrix = cosine_similarity(all_state_data_pca, all_state_data_pca[iowa_indices])\n",
    "\n",
    "# Define categories for dropdown list\n",
    "categories = sorted(restaurants_common[\"Category Title\"].unique())\n",
    "\n",
    "# Define the function to be called when a category is selected from the dropdown list\n",
    "def on_category_change(category, top_n):\n",
    "    category_dict = create_category_dict(restaurants_common)\n",
    "    top_restaurants_info = find_top_restaurants_info(category_dict, category, top_n)\n",
    "    \n",
    "    for i, restaurant_info in enumerate(top_restaurants_info, 1):\n",
    "        restaurant_name = restaurant_info['Name']\n",
    "        restaurant_city = restaurant_info['City']\n",
    "        restaurant_state = restaurant_info['State']\n",
    "\n",
    "        similar_cities = find_similar_cities_in_iowa(restaurant_city, all_state_demo, iowa_indices, cos_sim_matrix, 3)  # Always get top 3 similar cities\n",
    "        similar_cities = [city for city in similar_cities if city != restaurant_city]  # Exclude the restaurant's city\n",
    "        \n",
    "        print(f\"{i}. Restaurant: {restaurant_name} in {restaurant_city}, {restaurant_state}\")\n",
    "        print(f\"   Top 3 similar cities in Iowa:\")\n",
    "        for j, similar_city in enumerate(similar_cities, 1):  # Print top 3 similar cities\n",
    "            print(f\"   {j}. {similar_city}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "# Create dropdown widgets for category selection and top N selection\n",
    "category_dropdown = Dropdown(options=categories, description='Category:', style={'description_width': 'initial'})\n",
    "top_n_dropdown = Dropdown(options=[1, 2, 3], description='Top N:', style={'description_width': 'initial'})\n",
    "\n",
    "# Call the 'on_category_change' function when a category is selected\n",
    "interact(on_category_change, category=category_dropdown, top_n=top_n_dropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c429f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
